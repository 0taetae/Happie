### 2025.03.04 : 아이디어 구상
- 스마트홈
- 스마트물류/팩토리
- 스마트병원

### 2025.03.05 : 아이디어 구체화
- 스마트팜
    - 공간 관리
        - 물 주기, 텃밭 밀기 등등
    - 사용자와 연결
        - 사진 전송하여 텃밭의 상태 전달
- 스마트병원
    - 링거 홀대 + 휠체어 + 보행보조기 등 방치되는 기자재 관련 정리 및 위치 파악
    - 낙상 체크 및 알림
    - 간호사 호출 버튼
- 실버타운
    - 환경 관리
        - 타운 내 공원/정원/잔디 관리
        - 파크볼, 골프, 테니스 공 등 기자재 관리
    - 거주지 관리
        - 링거 홀대 / 휠체어 / 보행보조기 등 의료보조기 관리
        - 치매 예방이나 민원 기입 등

### 2025.03.06 : 팀 그라운드룰 설정, 사전학습
- 시뮬레이터
- ROS2
- Differential Drive
- OpenCV
- IMAGE 형식
- Custom Object
- Hand Control
- IMU
- 주행기록계(Odometry)
- Follow the carrot

### 2025.03.07 : ros2, 시뮬레이터 적응하기
- setup.bat, local_setup.bat을 call 하기
- colcon build 하기
- 시뮬레이터를 연결하여 데이터 확인하기

### 2025.03.10 : 요구사항 정의서, 시나리오 작성 

### 2025.03.11 : 와이어프레임, UI 제작 중

### 2025.03.12 : UI 1차 제작 완료, 역할 분배
![image](/uploads/2db1f2eaf1ea85a7a719dc3445d04ed2/image.png){width=906 height=311}

### 2025.03.13 : 시뮬레이터 1차 제작 확인, 자율주행 사전학습

### 2025.03.14 : UI 제작 수정, 시나리오 구체화 및 수정 

### 2025.03.17 : SLAM 학습
#### SLAM의 개념
- 로봇이나 자율주행 차량이 주변 환경을 실시간으로 인식하고 자신의 위치를 추정하며 지도를 작성하는 기술
1. Localization (위치 추정)
	- 로봇이 현재 어디에 있는지를 추정하는 과정
	- GPS, IMU, LiDAR, 카메라 센서 등을 활용
2. Mapping (지도 작성)
	- 로봇 주변의 환경을 매핑하여 지도를 만드는 과정
	- 2D/3D 공간 정보를 수집하여 맵을 구축

#### SLAM의 특징
- 실시간으로 Localization과 Mapping이 가능해야 한다.
- SLAM이 시작됨과 동시에 자신의 위치를 추정할 수 있다.
- SLAM이 종료됨과 동시에 자신의 이동기록계와 Map을 얻을 수 있다.
- 나의 위치가 전에 와본 위치인 것을 인식하고 Map의 오차 수정을 할 수 있다. 

#### SLAM의 작동 원리
1. 예측 단계
	- 이전 위치와 센서가 제공하는 움직임 정보를 기반으로 로봇의 새 위치를 추정
	
2. 보정 단계
    - 환경에서의 측정값을 사용하여 예측된 위치를 정제

-> 두 단계를 반복적으로 수행하여 로봇의 위치와 환경의 지도를 지속적으로 업데이트한다.

#### SLAM의 유형
1. Visual SLAM
	- 카메라 및 기타 영상 센서를 사용하여 주변 환경의 특징을 인식한다. 
    - 매 프레임마다 보이는 장애물과 사용중인 카메라의 상대적 위치를 계산해 누적함으로써, 시작점으로부터 현재의 나의 위치를 저장하는 방식 
    - 카메라 또는 IMU가 내장되어 있는 카메라 하나로 SLAM을 진행할 수 있다.
    - 카메라로는 주변 특징점 거리 파악을 하는 기능이 없거나 제한적이다. 
2. LiDAR SLAM
	- 3D 포인트 클라우드를 생성하여 주변 환경을 매핑한다.
    - 각 장면에 대한 특징점을 포인트 클라우드 형식으로 계산한다. 
3. 다중 센서 SLAM 
	- 여러 종류의 센서를 결합하여 정확성을 높인다.
